package main

import (
	"fmt"
	"net/http"
	"strconv"
	"strings"
	"time"

	"github.com/PuerkitoBio/goquery"
)

type haksikType struct {
	name string
	list []string
}

func trimInner(s string) string {
	returnString := ""
	for i, s := range strings.Split(s, "\n") {
		if s != "" {
			returnString += s
			if i != len(strings.Split(s, "\n")) {
				returnString += "\n"
			}
		}
	}
	return returnString
}

func (h *haksikType) toText() (text string) {
	text = ""
	êµ¬ë¶„ := [3]string{"ì •ì‹", "ì¼í’ˆ", "ì–‘ë¶„ì‹"}
	text += "\nâ—¼ " + h.name + "\n"
	for i, v := range h.list {
		//êµ¬ë¶„[i]
		text += "\nâ–ª " + êµ¬ë¶„[i] + "\n" + trimInner(v)
	}
	return
}

func crawlingHaksik(campus string) (text string) {
	fmt.Println(campus)
	text = ""
	res, err := http.Get(haksikEndpoint)
	if err != nil {
		fmt.Println("crawling(haksik): ", err)
	}

	doc, err := goquery.NewDocumentFromReader(res.Body)
	defer res.Body.Close()

	if err != nil {
		fmt.Println("query(haksik): ", err)
	}
	doc.Find(".gzTable").Each(func(i int, s *goquery.Selection) {
		// For each item found, get the band and title
		if i == 1 && campus == "ìŠ¹í•™" {
			ë¦¬ìŠ¤íŠ¸ := [5]haksikType{
				haksikType{"ë¶„ë¥˜", []string{}},
				haksikType{"êµìˆ˜íšŒê´€", []string{}},
				haksikType{"í•™ìƒíšŒê´€", []string{}},
				haksikType{"ê³µê³¼ëŒ€í•™", []string{}},
				haksikType{"ë„ì„œê´€", []string{}},
			}
			s.Find("td").Each(func(i int, s *goquery.Selection) {
				ë¦¬ìŠ¤íŠ¸[i%5].list = append(ë¦¬ìŠ¤íŠ¸[i%5].list, s.Text())
			})
			text += "ğŸ« ìŠ¹í•™ìº í¼ìŠ¤\n"
			for i, v := range ë¦¬ìŠ¤íŠ¸ {
				if i != 0 {
					text += v.toText()
				}
			}
		}

		if i == 2 && campus == "êµ¬ë•-ë¶€ë¯¼" {
			ë¦¬ìŠ¤íŠ¸ := [5]haksikType{
				haksikType{"ë¶„ë¥˜", []string{}},
				haksikType{"í•™ìƒíšŒê´€", []string{}},
				haksikType{"êµ­ì œíšŒê´€ ê¸°ìˆ™ì‚¬", []string{}},
				haksikType{"ë¶€ë¯¼(êµì§ì›)", []string{}},
				haksikType{"ê°•ì˜ë™ í•™ìƒíšŒê´€", []string{}},
			}

			s.Find("td").Each(func(i int, s *goquery.Selection) {
				ë¦¬ìŠ¤íŠ¸[i%5].list = append(ë¦¬ìŠ¤íŠ¸[i%5].list, s.Text())
			})
			text += "ğŸ« êµ¬ë•/ë¶€ë¯¼ ìº í¼ìŠ¤\n"
			for i, v := range ë¦¬ìŠ¤íŠ¸ {
				if i != 0 {
					text += v.toText()
				}
			}
		}
	})

	return
}

func crwalingLibrary() string {

	text := ""
	res, err := http.Get(libraryEndpoint)
	if err != nil {
		fmt.Println("crawling(library): ", err)
	}

	doc, err := goquery.NewDocumentFromReader(res.Body)
	defer res.Body.Close()

	if err != nil {
		fmt.Println("query(library): ", err)
	}

	li := []string{
		"0", "1", "2",
		"í•œë¦¼ ê·¸ë£¹ìŠ¤í„°ë””ì‹¤(4ì¸µ)", "í•œë¦¼ ì—´ëŒì‹¤A(5ì¸µ)", "í•œë¦¼ ì—´ëŒì‹¤B(5ì¸µ)",
		"í•œë¦¼ ì—´ëŒì‹¤C(5ì¸µ)", "í•œë¦¼ ì—´ëŒì‹¤D(5ì¸µ)", "í•œë¦¼ ì—´ëŒì‹¤E(ë…¸íŠ¸ë¶ ì—´ëŒì„)",
		"í•œë¦¼ ì—´ëŒì‹¤F(5ì¸µ)", "ë¶€ë¯¼ ì—´ëŒì‹¤1-A(5ì¸µ)", "ë¶€ë¯¼ ì—´ëŒì‹¤1-B(5ì¸µ)",
		"ë¶€ë¯¼ ì—´ëŒì‹¤2-A(6ì¸µ)", "ë¶€ë¯¼ ì—´ëŒì‹¤2-B(6ì¸µ)", "ë¶€ë¯¼ ì „ììë£Œì‹¤(7ì¸µ)",
		"ë¶€ë¯¼ ì—°ì†ê°„í–‰ë¬¼ì‹¤(8ì¸µ)", "ë¶€ë¯¼ ì¸ë¬¸ê³¼í•™ì‹¤(9ì¸µ)", "ë¶€ë¯¼ ì‚¬íšŒê³¼í•™ì‹¤(10ì¸µ)",
	}
	doc.Find("tr").Each(func(i int, s *goquery.Selection) {
		if i > 2 {
			text += li[i] + "\n"
			data := [3]string{}
			s.Find("td:nth-child(n+2):nth-child(-n+4) font").Each(func(i int, s *goquery.Selection) {
				data[i] = s.Text()
			})
			fmt.Println(data)
			text += "[" + data[1] + " / " + data[0] + " ] - ì”ì—¬ì¢Œì„(" + data[2] + " )\n\n"
		}
	})

	return text
}

func crawlingInformation() (text string) {
	text = ""
	res, err := http.Get(informationEndpoint)
	if err != nil {
		fmt.Println("crawling(library): ", err)
	}

	doc, err := goquery.NewDocumentFromReader(res.Body)
	defer res.Body.Close()

	if err != nil {
		fmt.Println("query(library): ", err)
	}

	doc.Find(".gzTable tr td:nth-child(-n+2)").Each(func(i int, s *goquery.Selection) {
		text += "ì”ì—¬: " + s.Text() + strings.Repeat("\n", i%2+1)
	})
	text = text[:len(text)-2]

	return
}

func getWeatherData(nx string, ny string) (string, string) {
	var weatherImage string
	var skyText string
	data := make(map[string]string)

	t := time.Now()
	fmt.Println(t.Format(time.RFC3339)[:10])
	fmt.Println(strconv.Itoa(t.Hour()))
	url := weatherEndpoint + "?" + "serviceKey=" + weatherKey + "&base_time=" + timeMapping[strconv.Itoa(t.Hour())] + "00&base_date=" + strings.ReplaceAll(t.Format(time.RFC3339)[:10], "-", "") + "&nx=" + nx + "&ny=" + ny
	res, err := http.Get(url)
	if err != nil {
		fmt.Println("crawling(weather): ", err)
	}

	doc, err := goquery.NewDocumentFromReader(res.Body)
	defer res.Body.Close()

	if err != nil {
		fmt.Println("query(weather): ", err)
	}

	fmt.Println(doc.Text())
	doc.Find("item").Each(func(index int, s *goquery.Selection) {
		category := s.Find("category").Text()
		value := s.Find("fcstValue").Text()
		fmt.Println(category, categoryMatching[category])
		data[categoryMatching[category]] = value
	})

	fmt.Println(data)
	fmt.Println(data["í•˜ëŠ˜ìƒíƒœ"])

	if data["í•˜ëŠ˜ìƒíƒœ"] == "1" {
		weatherImage = sunnyURL
		skyText = "\në‚ ì”¨: ë§‘ìŒ"
	} else if data["í•˜ëŠ˜ìƒíƒœ"] == "3" || data["í•˜ëŠ˜ìƒíƒœ"] == "4" {
		weatherImage = cloudyURL
		skyText = "\në‚ ì”¨: íë¦¼"
	} else if data["ê°•ìˆ˜í˜•íƒœ"] == "1" || data["ê°•ìˆ˜í˜•íƒœ"] == "4" {
		weatherImage = rainyURL
		skyText = "\në‚ ì”¨: ë¹„"
	} else if data["ê°•ìˆ˜í˜•íƒœ"] == "2" || data["ê°•ìˆ˜í˜•íƒœ"] == "3" {
		weatherImage = snowyURL
		skyText = "\në‚ ì”¨: ëˆˆ"
	} else {
		weatherImage = cloudyURL
		skyText = "\në‚ ì”¨ : ë¹„(" + data["ê°•ìˆ˜í™•ë¥ "] + "%)"
	}

	text := fmt.Sprintf("%s\nê¸°ì˜¨: %s", skyText, data["3ì‹œê°„ ê¸°ì˜¨"])
	if data["ê°•ìˆ˜í™•ë¥ "] != "" {
		text += "\nê°•ìˆ˜í™•ë¥ : " + data["ê°•ìˆ˜í™•ë¥ "] + "%"
	}

	if data["ìŠµë„"] != "" {
		text += "\nìŠµë„: " + data["ìŠµë„"] + "%"
	}
	// fmt.Println("NODATA: ", data["ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹"] == "")
	return weatherImage, text
}
